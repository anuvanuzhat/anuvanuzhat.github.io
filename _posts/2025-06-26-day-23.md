---
layout: post
title: "Day 23 â€“ A Little Too Perfect"
date: 2025-06-26
author: Anuva Nuzhat
permalink: /day23.html
tags: ["TD1", "RL", "Training", "DQN", "Dueling DQN"]

what_i_learned: >
  At the start of my day I began by running my code again with more episodes, except this time the accuracy levels were degrading and getting worse.
  I again started tweaking the hyperparameters to see if my accuracy could improve. After some changes like upping the learning rate and inital
  exploration I started getting consistent 100% accuracy on my training data. At first I was excited however after telling Dr. Dacon my faculty mentor
  he said this was actually a cause for concern. 100% accuracy is a little too perfect and he brough up many reasons for what could go wrong. The strong
  contestors are that the model is overfitting the specific data and is dependent on the data rather than the other way around. This would be a 
  big problem especially if we wanted to publish research as it is a huge red flag. The model should work regardless of the specific data and should
  not be so dependent or else it could do poorly on unseen data.
  

blockers: >
  Making sure my model is not too dependent on the specific data set we're working with and can adapt to unseen new data.
  
reflection: >
  Although I was excited yesterday a bit of it was short lived. I definitely improved from the struggles of the past days but the issues are not over just yet.
  Even though I was able to achieve a high accuracy it might have been a little too perfect and actually a sign of a weak model. One of the issues I think it 
  might be was that I did not add any noise to my environment so I added some and my accuracy fell to 76%. I still need to run it a couple more times to see
  how consistent that accuracy is but if it is then I need to work on putting another plan into action to successfully get it to a higher accuracy that is not
  a cause for concern. 
  
---
